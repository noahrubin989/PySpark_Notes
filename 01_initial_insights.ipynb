{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47fd9110",
   "metadata": {},
   "source": [
    "## PySpark Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad128789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import Row, SparkSession\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396931f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://noahs-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Intro</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f93257337c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark Intro\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886138d2",
   "metadata": {},
   "source": [
    "#### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff023ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da703e3",
   "metadata": {},
   "source": [
    "#### Display dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4213c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------------+---------------+\n",
      "|       _c0|         _c1|             _c2|            _c3|\n",
      "+----------+------------+----------------+---------------+\n",
      "|Order Date|Total Profit|         Country|      Item Type|\n",
      "|2012-07-27|     3839.13|    South Africa|         Fruits|\n",
      "|2013-09-14|   338631.84|         Morocco|        Clothes|\n",
      "|2015-05-15|     20592.0|Papua New Guinea|           Meat|\n",
      "|2017-05-17|    41273.28|        Djibouti|        Clothes|\n",
      "|2016-10-26|    62217.18|        Slovakia|      Beverages|\n",
      "|2011-11-07|     3323.39|       Sri Lanka|         Fruits|\n",
      "|2013-01-18|     9349.02|     Seychelles |      Beverages|\n",
      "|2016-11-30|    23114.16|        Tanzania|      Beverages|\n",
      "|2017-03-23|    113120.0|           Ghana|Office Supplies|\n",
      "+----------+------------+----------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722a1b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='Order Date', _c1='Total Profit', _c2='Country', _c3='Item Type'),\n",
       " Row(_c0='2012-07-27', _c1='3839.13', _c2='South Africa', _c3='Fruits'),\n",
       " Row(_c0='2013-09-14', _c1='338631.84', _c2='Morocco', _c3='Clothes'),\n",
       " Row(_c0='2015-05-15', _c1='20592.0', _c2='Papua New Guinea', _c3='Meat'),\n",
       " Row(_c0='2017-05-17', _c1='41273.28', _c2='Djibouti', _c3='Clothes'),\n",
       " Row(_c0='2016-10-26', _c1='62217.18', _c2='Slovakia', _c3='Beverages'),\n",
       " Row(_c0='2011-11-07', _c1='3323.39', _c2='Sri Lanka', _c3='Fruits'),\n",
       " Row(_c0='2013-01-18', _c1='9349.02', _c2='Seychelles ', _c3='Beverages'),\n",
       " Row(_c0='2016-11-30', _c1='23114.16', _c2='Tanzania', _c3='Beverages'),\n",
       " Row(_c0='2017-03-23', _c1='113120.0', _c2='Ghana', _c3='Office Supplies')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also an option\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134b804",
   "metadata": {},
   "source": [
    "#### Read in the data, but have the columns be displayed properly rather than _c0, _c1 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e2fbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------------+---------------+\n",
      "|Order Date|Total Profit|         Country|      Item Type|\n",
      "+----------+------------+----------------+---------------+\n",
      "|2012-07-27|     3839.13|    South Africa|         Fruits|\n",
      "|2013-09-14|   338631.84|         Morocco|        Clothes|\n",
      "|2015-05-15|     20592.0|Papua New Guinea|           Meat|\n",
      "|2017-05-17|    41273.28|        Djibouti|        Clothes|\n",
      "|2016-10-26|    62217.18|        Slovakia|      Beverages|\n",
      "|2011-11-07|     3323.39|       Sri Lanka|         Fruits|\n",
      "|2013-01-18|     9349.02|     Seychelles |      Beverages|\n",
      "|2016-11-30|    23114.16|        Tanzania|      Beverages|\n",
      "|2017-03-23|    113120.0|           Ghana|Office Supplies|\n",
      "|2016-05-23|  1350622.16|        Tanzania|      Cosmetics|\n",
      "+----------+------------+----------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "This df_new object is of type: <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_new = spark.read.option(key='header', value='true').csv('sales.csv')\n",
    "df_new.show(n=10)\n",
    "print(f\"This df_new object is of type: {type(df_new)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41049f7d",
   "metadata": {},
   "source": [
    "#### Get info on our dataset (similar to `df.info()` in pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e000d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Total Profit: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Item Type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
